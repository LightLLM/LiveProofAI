# LiveProof AI â€“ one-command local run
# Usage: docker compose up -d
# Web: http://localhost:3000  API: http://localhost:8000

services:
  api:
    build:
      context: .
      dockerfile: apps/api/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - YOU_STUB=true
      - SANITY_PROJECT_ID=${SANITY_PROJECT_ID:-}
      - SANITY_DATASET=${SANITY_DATASET:-production}
      - SANITY_TOKEN=${SANITY_TOKEN:-}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    depends_on:
      api:
        condition: service_healthy

  # Optional: GPU worker (embedding service). Requires nvidia-docker on host.
  # worker:
  #   build:
  #     context: .
  #     dockerfile: apps/worker/Dockerfile
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
